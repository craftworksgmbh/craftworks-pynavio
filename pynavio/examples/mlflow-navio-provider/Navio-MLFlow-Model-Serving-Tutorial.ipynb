{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to prepare a Mlflow Model for Navio Deployment\n",
    "\n",
    "This notebook shows how to wrap a custom inference pipeline into a mlflow model ready for deployment on navio.\n",
    "xgboost, pandas, sklearn and numpy needs to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test datasets\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = pd.DataFrame(data= iris['data'], columns= [\"x1\",\"x2\",\"x3\",\"x4\"])\n",
    "y = pd.DataFrame(data= iris['target'], columns= [\"y\"])\n",
    "x_train, x_test, y_train, _ = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "# Training model\n",
    "xgb_model = xgb.XGBClassifier(params={'max_depth': 10})\n",
    "xgb_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup notebook\n",
    "if os.path.exists(\"temp\"):\n",
    "    shutil.rmtree(\"temp\")\n",
    "os.makedirs(\"temp\")\n",
    "\n",
    "\n",
    "xgb_model_path = \"temp/xgb_model.pkl\"\n",
    "pickle.dump(xgb_model, open(xgb_model_path, 'wb'))\n",
    "\n",
    "standard_scaler_path = 'temp/scaler.pkl'\n",
    "pickle.dump(sc, open(standard_scaler_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "This is how the data scientist needs to design his pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mlflow.pyfunc\n",
    "import json\n",
    "import cloudpickle\n",
    "import pip\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide schema for navio. \n",
    "\n",
    "This schema is not used by mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_request = {\n",
    "    \"featureColumns\":  [\n",
    "        {\n",
    "            \"name\": \"x1\",\n",
    "            \"sampleData\": 5.1,\n",
    "            \"type\": \"float\",\n",
    "            \"nullable\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x2\",\n",
    "            \"sampleData\": 3.5,\n",
    "            \"type\": \"float\",\n",
    "            \"nullable\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x3\",\n",
    "            \"sampleData\": 1.4,\n",
    "            \"type\": \"float\",\n",
    "            \"nullable\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x4\",\n",
    "            \"sampleData\": 0.2,\n",
    "            \"type\": \"float\",\n",
    "            \"nullable\": False\n",
    "        }\n",
    "    ],\n",
    "    \"targetColumns\": [\n",
    "        {\n",
    "            \"name\": \"y\",\n",
    "            \"sampleData\": 5.1,\n",
    "            \"type\": \"float\",\n",
    "            \"nullable\": False\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "EXAMPLE_REQUEST_PATH = 'temp/example_request.json'\n",
    "\n",
    "with open(EXAMPLE_REQUEST_PATH, 'w') as file:\n",
    "    json.dump(example_request, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Conda environment for the new MLflow Model that contains the XGBoost library\n",
    "# as a dependency, as well as the required CloudPickle library\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "        'python={}'.format(sys.version.split(' ')[0]),\n",
    "        'pip={}'.format(pip.__version__),\n",
    "        {\n",
    "            'pip': [\n",
    "                'mlflow=={}'.format(mlflow.__version__), # otherwise --install-mlflow is required\n",
    "                'scikit-learn=={}'.format(sklearn.__version__),\n",
    "                'xgboost=={}'.format(xgb.__version__),\n",
    "                'numpy=={}'.format(np.__version__)\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    'name': 'my_env'\n",
    "}\n",
    "conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an `artifacts` dictionary that assigns a unique name to the saved XGBoost model file.\n",
    "# This dictionary will be passed to `mlflow.pyfunc.save_model`, which will copy the model file\n",
    "# into the new MLflow Model's directory.\n",
    "artifacts = {\n",
    "    \"xgb_model\": xgb_model_path,\n",
    "    \"standard_scaler\": standard_scaler_path,\n",
    "    \"example_request\": EXAMPLE_REQUEST_PATH\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"./src\" # This is where the actual code is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.custom_pipeline import CustomPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\"\"\"\n",
    "Generic Mlflow Model Class that just wraps the custom class\n",
    "\n",
    "If this class is not defined in __main__ mlflow will not find it.\n",
    "-> Solution: Add it to the code_path. if it is within src it would also work for example\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MlFlowInference(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def load_context(self, context) -> None:\n",
    "        from src.inference.custom_pipeline import CustomPipeline\n",
    "\n",
    "        self.model = CustomPipeline(artifacts=context.artifacts)\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame) -> dict:\n",
    "        pred = self.model.predict(model_input)\n",
    "        return {\"prediction\": pred.tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the MLflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow_pyfunc_model_path = \"mlflow-template/mlflow-custom-pipeline\"\n",
    "\n",
    "if os.path.exists(mlflow_pyfunc_model_path):\n",
    "    shutil.rmtree(mlflow_pyfunc_model_path)\n",
    "\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=mlflow_pyfunc_model_path,\n",
    "    python_model=MlFlowInference(),\n",
    "    artifacts=artifacts,\n",
    "    conda_env=conda_env,\n",
    "    code_path=[src_path] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a zip for navio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shutil.make_archive(mlflow_pyfunc_model_path, 'zip', mlflow_pyfunc_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inference in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the model in `python_function` format\n",
    "loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test request\n",
    "test_input = x[:10].to_dict(orient='split') # this is what we send in the json request\n",
    "test_input_df = pd.DataFrame(test_input[\"data\"], columns=test_input[\"columns\"]) # this is how mlflow loads it in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_predictions = loaded_model.predict(test_input_df)\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup notebook\n",
    "if os.path.exists(\"temp\"):\n",
    "    shutil.rmtree(\"temp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test serving before deploying on navio\n",
    "\n",
    "In the commandline run:\n",
    "\n",
    "    mlflow models serve -m mlflow-template/mlflow-custom-pipeline -p 5001 --install-mlflow\n",
    "    curl http://127.0.0.1:5001/invocations -H 'Content-Type: application/json' -d '{\"columns\": [\"x1\", \"x2\", \"x3\", \"x4\"],\"data\": [[4.1, 5.1, 6.1, -4.1], [4.1, 5.1, 6.1, -4.1]]}'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
